{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM1YQ6qFJ3AR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Flatten, AveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "IMG_SIZE = 227\n",
        "DATA_PATH = 'D:\\\\Destination\\\\dataset'\n",
        "CATEGORIES = [\"New_Front\", \"New_Rear\", \"Old_Front\", \"Old_Rear\"]"
      ],
      "metadata": {
        "id": "zfCuRMVOKJ3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create training data\n",
        "def create_training_data(data_path, categories):\n",
        "    training_data = []\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_path, category)\n",
        "        class_num = categories.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path, img))\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "    return training_data\n",
        "\n",
        "# Create training data\n",
        "training_data = create_training_data(DATA_PATH, CATEGORIES)"
      ],
      "metadata": {
        "id": "pCmWRe18KdpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and separate features and labels\n",
        "np.random.shuffle(training_data)\n",
        "X, y = zip(*training_data)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255.0\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "1s6uDjhWKjFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "validation_split = 0.1\n",
        "split_index = int(len(X) * (1 - validation_split))\n",
        "train_images, validation_images = X[:split_index], X[split_index:]\n",
        "train_labels, validation_labels = y[:split_index], y[split_index:]\n",
        "\n",
        "# Convert labels to categorical format\n",
        "train_labels = to_categorical(train_labels, num_classes=len(CATEGORIES))\n",
        "validation_labels = to_categorical(validation_labels, num_classes=len(CATEGORIES))"
      ],
      "metadata": {
        "id": "aei6fKctK2eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))"
      ],
      "metadata": {
        "id": "WmzA4BWmK_xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function for image processing in the dataset\n",
        "def process_images(image, label):\n",
        "    image = tf.image.per_image_standardization(image)\n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "1DjOipqrMDXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply image processing to datasets\n",
        "batch_size = 32\n",
        "train_ds = train_ds.map(process_images).batch(batch_size=batch_size, drop_remainder=True)\n",
        "validation_ds = validation_ds.map(process_images).batch(batch_size=batch_size, drop_remainder=True)"
      ],
      "metadata": {
        "id": "qtJ9MxnjMFP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "base_model = MobileNetV2(input_shape=[IMG_SIZE, IMG_SIZE, 3], weights=\"imagenet\", include_top=False)\n",
        "x = base_model.output\n",
        "x = AveragePooling2D(pool_size=(7, 7))(x)\n",
        "x = Flatten(name=\"flatten\")(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(4096, activation='sigmoid')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(len(CATEGORIES), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=output)"
      ],
      "metadata": {
        "id": "WOerQJEuK5wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)\n",
        "\n",
        "# Save the model and weights\n",
        "model.save('brake_disc_model.h5')"
      ],
      "metadata": {
        "id": "MwGOrD_CMLYg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
